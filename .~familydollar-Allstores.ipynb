{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from pandas import DataFrame as df\n",
    "import pandas as pd\n",
    "\n",
    "cities = []\n",
    "cities_href = []\n",
    "stores= []\n",
    "store_links = []\n",
    "store_url = \"\"\n",
    "\n",
    "states_href = []\n",
    "page = requests.get(\"https://www.familydollar.com/locations/\")\n",
    "soup = BeautifulSoup(page.content,\"html.parser\")\n",
    "\n",
    "# parse html to get all the state links\n",
    "states_info = soup.find_all(class_ = 'itemlist')\n",
    "for state in states_info:\n",
    "    states_href.append(state.a[\"href\"])\n",
    "    \n",
    "\n",
    "for state in states_href:\n",
    "    state_page = requests.get(state)\n",
    "    state_soup = BeautifulSoup(state_page.content,\"html.parser\")\n",
    "\n",
    "#     parse to get store links in a city\n",
    "    city_list_parent = state_soup.find_all(class_ = 'itemlist')\n",
    "    for d in city_list_parent:\n",
    "        cities.append(d.a.get_text())\n",
    "        cities_href.append(d.a['href'])  \n",
    "    \n",
    "#     parse to get a detailed link\n",
    "for store in cities_href:\n",
    "    store_page = requests.get(store)\n",
    "    store_soup = BeautifulSoup(store_page.text,\"html.parser\")\n",
    "\n",
    "\n",
    "    store_info = store_soup.find_all(type=\"application/ld+json\")    \n",
    "    for i in store_info:\n",
    "        storecont = i.contents[0]\n",
    "        storejson = json.loads(storecont)\n",
    "\n",
    "    try:\n",
    "        store_url = storejson['url']    \n",
    "        store_links.append(store_url)            \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #     parse to get address and geo code of each store\n",
    "    store_geopage = requests.get(store_url)\n",
    "    store_geosoup = BeautifulSoup(store_geopage.text,\"html.parser\")\n",
    "\n",
    "    store_geoinfo = store_geosoup.find_all(type=\"application/ld+json\") \n",
    "    for geo_i in store_geoinfo:\n",
    "        store_geocont = geo_i.contents[0]\n",
    "        store_geojson = json.loads(store_geocont)\n",
    "        try:\n",
    "            store_geoaddr = store_geojson['address']            \n",
    "            store_geoaddr.update(store_geojson['geo'])\n",
    "            store_geoaddr[\"link\"] = store_geojson['url']\n",
    "            stores.append(store_geoaddr)\n",
    "        except:\n",
    "            pass   \n",
    "\n",
    "stores_df = df.from_records(stores)\n",
    "# drop unnecessary info from dataframe\n",
    "stores_df.drop(['@type', 'addressCountry'], axis = 1, inplace = True)\n",
    "stores_df['Store'] = \"Family Dollar\"\n",
    "stores_df.to_csv(\"FamilyDollar-AllStores.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
